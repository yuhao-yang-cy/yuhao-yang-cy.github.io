<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Neural Style Transfer (Deep Learning Notes C4W4) | Colin Young's Personal Site </title> <meta name="author" content="Colin Young"> <meta name="description" content="generation of an image that blends the content from one image and the style of the other"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yuhao-yang-cy.github.io//blog/2026/deep-C4W4-NST/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Colin Young's Personal Site </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/bio/">bio </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">posts </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">bookshelf </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">logs </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Neural Style Transfer (Deep Learning Notes C4W4)</h1> <p class="post-meta"> Created on January 06, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/cnn"> <i class="fa-solid fa-hashtag fa-sm"></i> CNN</a>   <a href="/blog/tag/computer-art"> <i class="fa-solid fa-hashtag fa-sm"></i> computer-art</a>   ·   <a href="/blog/category/machine-learning"> <i class="fa-solid fa-tag fa-sm"></i> machine-learning</a>   <a href="/blog/category/computer-science"> <i class="fa-solid fa-tag fa-sm"></i> computer-science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <blockquote> <p>These are some notes for the Coursera Course on <a href="https://www.coursera.org/learn/convolutional-neural-networks" rel="external nofollow noopener" target="_blank">Convolutional Neural Networks</a>, which is a part of the <a href="https://www.coursera.org/specializations/deep-learning" rel="external nofollow noopener" target="_blank">Deep Learning Specialization</a>. This post is a summary of the course contents that I learned from Week 4.</p> <p>These notes are far from original. All credits go to the course instructor Andrew Ng and his team.</p> </blockquote> <h2 id="neural-style-transfer-overview">Neural Style Transfer: Overview</h2> <p>The goal of <strong>Neural Style Transfer</strong> (NST) is to merge two images, a <strong>content image</strong> (\(C\)) and a <strong>style image</strong> (\(S\)), to create a <strong>generated image</strong> (\(G\)) such that the generated image \(G\) combines the content of the image \(C\) with the style of image \(S\).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deep/C4W4_style_transfer-480.webp 480w,/assets/img/deep/C4W4_style_transfer-800.webp 800w,/assets/img/deep/C4W4_style_transfer-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/deep/C4W4_style_transfer.jpg" class="img-natural rounded z-depth-1" width="100%" height="auto" title="Nerual Style Transfer" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Nerual Style Transfer </div> <p>This is implemented by extracting the content statistics of the content image \(C\) and the style statistics of the style image \(S\) using a deep convolutional network, and then optimizing the output image \(G\) to match these statistics.</p> <h2 id="choosing-the-layers-of-the-model">Choosing the Layers of the Model</h2> <p>Starting from the network’s input layer, the first few layer activations represent low-level features like edges, corner and simple textures. As we step through the network, the deeper layers detect higher-level features like parts of specific objects and more complex patterns.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deep/C4W4_viz_cnns-480.webp 480w,/assets/img/deep/C4W4_viz_cnns-800.webp 800w,/assets/img/deep/C4W4_viz_cnns-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/deep/C4W4_viz_cnns.jpg" class="img-natural rounded z-depth-1" width="100%" height="auto" title="Layers of a CNN" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Layers of a Typical CNN </div> <p>Nerual Style Transfer uses <em>intermediate layers</em> of a pre-trained image classification network such as the VGG19 network, so that the content representation contains information about the image’s structures and objects while discarding specific details that are not relevant to the main objective. Choosing intermediate layers allows the NST algorithm to control the balance between preserving the content image’s structure and applying the style image’s aesthetic.</p> <h2 id="cost-functions-for-nst">Cost Functions for NST</h2> <p>The cost function that we use for the NST algorithm contains two terms:</p> <ul> <li>a <strong>content cost function</strong> \(J_\text{content}(C,G)\) that measures the similiarity between the contents of \(C\) and \(G\)</li> <li>a <strong>style cost function</strong> \(J_\text{style}(S,G)\) that measures the similarity between the styles of \(S\) and \(G\)</li> </ul> <p>Then the total cost is defined as the linear combination of the two</p> \[J(G) = \alpha J_\text{content}(C,G) + \beta J_\text{style}(S,G)\] <h2 id="content-cost-function-j_textcontentcg">Content Cost Function \(J_\text{content}(C,G)\)</h2> <p>The generated image G should match the content of image C. The content cost function can be defined as:</p> \[J_\text{content}(C,G) = \frac{1}{4 \times n_H \times n_W \times n_C}\sum _{ \text{all entries}} (a^{(C)} - a^{(G)})^2 \tag{1}\] <p>Here, \(n_H, n_W\) and \(n_C\) are the height, width and number of channels of the intermediate hidden layer we have chosen, and appear as a normalization term in the cost. The terms \(a^{(C)}\) and \(a^{(G)}\) are the 3D volumes corresponding to a hidden layer’s activations of the neural network. The content cost then measures how different \(a^{(C)}\) and \(a^{(G)}\) are. When we minimize the content cost later, this will help make sure \(G\) has similar contents as \(C\).</p> <p>In order to compute the cost \(J_\text{content}(C,G)\), it might also be convenient to <em>unroll</em> these 3D volumes into a 2D matrix, as shown below. Technically this unrolling step is not necessary for computing \(J_\text{content}\), but it will be good practice for when we carry out a similar operation later for computing the style cost \(J_\text{style}\).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deep/C4W4_NST_Unrolling-480.webp 480w,/assets/img/deep/C4W4_NST_Unrolling-800.webp 800w,/assets/img/deep/C4W4_NST_Unrolling-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/deep/C4W4_NST_Unrolling.jpg" class="img-natural rounded z-depth-1" width="100%" height="auto" title="Unrolling a 3D Layer" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Unrolling a 3D Layer </div> <h2 id="style-matrix">Style Matrix</h2> <p>The style of an image can be represented using the Gram matrix of an intermediate layer’s activations.</p> <p>In linear algebra, the <strong>Gram matrix</strong> \(\mathbf{G}\) of a set of vectors \((v_{1},\dots ,v_{n})\) is the matrix of dot products, whose entries are</p> \[\mathbf{G}_{ij} = v_{i}^T v_{j} = \text{np.dot}(v_{i}, v_{j})\] <p>In NST, we compute the Style matrix by multiplying the unrolled filter matrix with its transpose</p> \[\mathbf{G}_\text{gram} = \mathbf{A}_\text{unrolled} \mathbf{A}_\text{unrolled}^T\] <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deep/C4W4_NST_GM-480.webp 480w,/assets/img/deep/C4W4_NST_GM-800.webp 800w,/assets/img/deep/C4W4_NST_GM-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/deep/C4W4_NST_GM.jpg" class="img-natural rounded z-depth-1" width="100%" height="auto" title="Gram Matrix Multiplication" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Gram Matrix Multiplication </div> <p>In components, supopse the activation at row \(i\), column \(j\) and channel \(k\) at a chosen hidden layer is represented by \(a_{i,j,k}\), then the matrix element of \(\mathbf{G}_\text{gram}\) is:</p> \[\mathbf{G}_{\text{(gram)}{k,k'}} = \sum_{i=1}^{n_H} \sum_{j=1}^{n_W} a_{i,j,k} \,a_{i,j,k'}\] <p>The result will be a matrix of dimension \(n_C \times n_C\) where \(n_C\) is the number of channels of that intermediate layer.</p> <p>The matrix element \(\mathbf{G}_{k,k'}\) compares how similar the activations from the filter \(k\) is to those activations from the filter \(k'\). If \(a_k\) and \(a_{k'}\) are highly correlated, their dot product should be large and thus we expect the matrix element \(\mathbf{G}_{k,k'}\) to be large.</p> <p>Also, the diagonal elements \(\mathbf{G}_{k,k}\) measures the level of activity of the filter \(k\). If \(\mathbf{G}_{k,k}\) is large, then this means the image contains a lot of features as represented by the channel \(k\).</p> <p>By capturing the prevalence of different types of features (\(\mathbf{G}_{k,k}\)) as well as how much different features occur together (\(\mathbf{G}_{k,k'}\)), the matrix \(\mathbf{G}_\text{gram}\) measures the style of the image.</p> <h2 id="style-cost">Style Cost</h2> <p>After calculating the Gram matrix, the next goal is to minimize the distance between the Gram matrix of the style image \(S\) and the Gram matrix of the generated image \(G\).</p> <p>For a single hidden layer, we can compute the Gram matrices of the style image \(S\) and the generated image \(G\), that is \(\mathbf{G}_\text{gram}^{(S)}\) and \(\mathbf{G}_\text{gram}^{(G)}\), using the activations \(a^{[l]}\) from this particular intermediate layer in the network. The corresponding style cost is defined as:</p> \[J_\text{style}^{[l]}(S,G) = \frac{1}{4 \times {n_C}^2 \times (n_H \times n_W)^2} \sum _{k=1}^{n_C}\sum_{k'=1}^{n_C}(\mathbf{G}^{(S)}_{\text{(gram)}k,k'} - \mathbf{G}^{(G)}_{\text{(gram)}k,k'})^2\tag{2}\] <p>Better results can be obtained if the representation of the style image \(S\) is computed from multiple different layers and combined. The style costs from several different layers can be merged to give:</p> \[J_\text{style}(S,G) = \sum_{l} \lambda^{[l]} J^{[l]}_\text{style}(S,G)\] <p>where \(\lambda^{[l]}\) are the weights that reflect how much each layer contributes to the style and they are subject to the normalisation condition \(\sum_{l=1}^L\lambda^{[l]} = 1\).</p> <p>The choice of the coefficients for each layer depends on how much we want the generated image to follow the style image. Since deeper layers capture higher-level concepts, and the features in the deeper layers are less localized in the image relative to each other, so if we want to follow the style image softly, larger weights for deeper layers and smaller weights for the earlier layers can be chosen. In contrast, if we want the generated image to strongly follow the style image, we may choose smaller weights for deeper layers and larger weights for the earlier layers.</p> <h2 id="total-cost">Total Cost</h2> <p>The content cost and the style cost functions are combined to give the total cost:</p> \[J(G) = \alpha J_\text{content}(C,G) + \beta J_\text{style}(S,G)\] <p>Here \(\alpha\) and \(\beta\) are hyperparameters that control the relative weighting between content and style.</p> <p>By loading the VGG19 model and choosing a suitable optimizer for the total cost, we are able to implement Neural Style Transfer and generate artistic images with lots of fun!</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deep/C4W4_antelope_NST-480.webp 480w,/assets/img/deep/C4W4_antelope_NST-800.webp 800w,/assets/img/deep/C4W4_antelope_NST-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/deep/C4W4_antelope_NST.jpg" class="img-natural rounded z-depth-1" width="100%" height="auto" title="Style Transfer with Customised Images" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Style Transfer with Customised Images </div> </div> </article> </div> <style>.img-natural{max-width:90%;width:auto!important;height:auto;display:block;margin-left:auto;margin-right:auto}h2{color:var(--global-bg-color);background:var(--global-theme-color);line-height:1.6em;border-radius:3px;padding:2px;display:inline-block}</style> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Colin Young. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>